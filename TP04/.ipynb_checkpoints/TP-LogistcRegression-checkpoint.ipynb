{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session on logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install plotly_express\n",
    "import plotly_express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "from plotly.offline import plot, iplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Logistic regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set notebook mode\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    # Z = X*w+p => h(x)\n",
    "    def __init__(self, x_train, y_train, w, b, numOfTrainingItems, learning_rate):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.numOfTrainingItems = numOfTrainingItems\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Sigmoid Function (Z = w*X+p) .. w=theta1 , p=theta0\n",
    "    def Sigmoid_Hypothesis(self, w, x, b):\n",
    "        z = ## YOUR CODE HERE\n",
    "        return 1 / (1 + np.e ** -z)\n",
    "\n",
    "    # Cost Function\n",
    "    def Cost_Function(self):\n",
    "        hypothesis = self.Sigmoid_Hypothesis(self.w, self.x_train, self.b)\n",
    "        return np.dot((self.x_train.T, self.y_train - hypothesis))\n",
    "\n",
    "    # get the values of w,b by gradient descent\n",
    "    def gradient_descent(self):\n",
    "        hypothesis = self.Sigmoid_Hypothesis(self.w, self.x_train, self.b)\n",
    "        self.w += (self.learning_rate * ## YOUR CODE HERE / numOfTrainingItems)\n",
    "        self.b += (self.learning_rate * ## YOUR CODE HERE / numOfTrainingItems)\n",
    "        return [self.w, self.b]\n",
    "\n",
    "    # training the data\n",
    "    def train(self):\n",
    "        for i in range(10000):\n",
    "            self.w, self.b = self.gradient_descent()\n",
    "        return [self.w, self.b]\n",
    "\n",
    "    # predict new values\n",
    "    def predict(self, x_test):\n",
    "        hypothesis = self.Sigmoid_Hypothesis(self.w, x_test, self.b)\n",
    "        return [1 if val >= 0.5 else 0 for val in hypothesis]\n",
    "\n",
    "    def calc_accuracy(self, y_test, y_predicted):\n",
    "        cnt = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i] == y_predicted[i]:\n",
    "                cnt += 1\n",
    "        return cnt / len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First test on consumer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data (req1)\n",
    "customerData = pd.read_csv('./customer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shuffle the data\n",
    "customerData.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X => values of features 1,2 (age, salary) & Y => values of output (purchased)\n",
    "NumberOfFeatures=2\n",
    "X = customerData.iloc[:, 0:2].values\n",
    "Y = customerData.iloc[:, 2:3].values\n",
    "# random initial values for w and b\n",
    "w = np.random.random((NumberOfFeatures, 1))\n",
    "b = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling using minmax normalization\n",
    "X0_temp = []\n",
    "X1_temp = []\n",
    "for i in X:\n",
    "    X0_temp.append(i[0])\n",
    "    X1_temp.append(i[1])\n",
    "minVal = min(X0_temp)\n",
    "maxVal = max(X0_temp)\n",
    "for i in range(len(X0_temp)):\n",
    "    X0_temp[i] = (X0_temp[i] - minVal) / (maxVal - minVal)\n",
    "\n",
    "minVal = min(X1_temp)\n",
    "maxVal = max(X1_temp)\n",
    "for i in range(len(X1_temp)):\n",
    "    X1_temp[i] = (X1_temp[i] - minVal) / (maxVal - minVal)\n",
    "\n",
    "X = X.astype(float)\n",
    "for i in range(len(X)):\n",
    "    X[i][0] = (X0_temp[i])\n",
    "    X[i][1] = (X1_temp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (req2)\n",
    "X_Train = X[0:320]\n",
    "Y_Train = Y[0:320]\n",
    "X_Test = X[320:]\n",
    "Y_Test = Y[320:]\n",
    "numOfTrainingItems = int(X_Train.size / 2)\n",
    "print(\"Number of training points: \",numOfTrainingItems)\n",
    "print(\"X train shape:\",X_Train.shape)\n",
    "print(\"Y train shape:\",Y_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression (req3)\n",
    "LogisticReg = LogisticRegression(X_Train, Y_Train, w, b, numOfTrainingItems, 0.2)\n",
    "w, b = LogisticReg.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: try with other splitting options for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on new data (req4)\n",
    "Y_Predict = LogisticReg.predict(X_Test)\n",
    "print(f\"{Y_Predict}\")\n",
    "\n",
    "# Calculate the accuracy (req5)\n",
    "print(f\"Accuracy : {LogisticReg.calc_accuracy(Y_Test, Y_Predict) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second test on scikitlearn classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0,max_iter=500).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: try with other settings, inspect the scikit-learn documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
